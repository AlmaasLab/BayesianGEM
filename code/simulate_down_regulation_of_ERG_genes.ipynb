{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import GEMS\n",
    "import os\n",
    "from multiprocessing import Process,cpu_count,Manager\n",
    "from etcpy import etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gene_names():\n",
    "    gene_names = dict()\n",
    "    gene_ids = dict()\n",
    "    for line in open('../data/enzyme_uniprot_gene_name.csv'):\n",
    "        cont = line.strip().split(',')\n",
    "        gene_names[cont[0]] = cont[1]\n",
    "        gene_ids[cont[1]] = cont[0]\n",
    "    return gene_names,gene_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names,gene_ids = load_gene_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_erg_rxns(model):\n",
    "    ERG_genes = ['ERG10','ERG13','HMG1','HMG2','ERG12','ERG8','MVD1','IDI1','ERG20',\n",
    "             'ERG9','ERG7','ERG11','ERG24','ERG25','ERG26','ERG27','ERG6','ERG2',\n",
    "             'ERG3','ERG5','ERG4'] # MVD1 is ERG19\n",
    "    rxns = []\n",
    "    for g in ERG_genes: \n",
    "        uni = gene_ids[g]\n",
    "        met_prot = model.metabolites.get_by_id('prot_{0}'.format(uni))\n",
    "        lst = [rxn.id for rxn in met_prot.reactions if 'prot_pool' not in rxn.reaction]\n",
    "        rxns.extend(lst)\n",
    "    return rxns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_temperature_constraints(model,particle,T):\n",
    "    df,_ = GEMS.format_input(particle)\n",
    "    \n",
    "    etc.map_fNT(model,T,df)\n",
    "    etc.map_kcatT(model,T,df)\n",
    "    etc.set_NGAMT(model,T)\n",
    "    etc.set_sigma(model,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maximal_flux_through_given_rxn(model,rxn_id,growth_id):\n",
    "\n",
    "    with model:\n",
    "        rmax = model.optimize().objective_value\n",
    "        model.reactions.get_by_id(growth_id).upper_bound = rmax*0.999\n",
    "        \n",
    "        model.objective = rxn_id\n",
    "        model.objective.direction = 'max'\n",
    "        vmax = model.optimize().objective_value\n",
    "\n",
    "    return vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_regulate_erg_genes(model,erg_vmax,p_down):\n",
    "    # p_down, percentage of down regulation\n",
    "    # erg_vmax, {rxn_id, vmax}\n",
    "    for rxn_id, vmax in erg_vmax.items():\n",
    "        model.reactions.get_by_id(rxn_id).upper_bound = vmax*p_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_one_particle(particle,T,ps):\n",
    "    growth_id = 'r_2111'\n",
    "    print('Load model')\n",
    "    mae = pickle.load(open('../models/aerobic.pkl','rb'))\n",
    "    \n",
    "    # get ori coeffs for ERG1\n",
    "    met1 = mae.metabolites.get_by_id('prot_{0}'.format('P32476'))\n",
    "    old_kcat_coeffs = {rxn.id: rxn.get_coefficient(met1) for rxn in met1.reactions}\n",
    "            \n",
    "    met2 = mae.metabolites.prot_pool\n",
    "    rxn = mae.reactions.get_by_id('draw_prot_{0}'.format('P32476'))\n",
    "    old_fnt_coeff = rxn.get_coefficient(met2)\n",
    "    \n",
    "    print('Set temperature constraits')\n",
    "    set_temperature_constraints(mae,particle,T)\n",
    "    erg_rxns = get_erg_rxns(mae)\n",
    "    \n",
    "    print('Get vmax')\n",
    "    # This is to avoid some unbounded results\n",
    "    for rxn_id in erg_rxns:\n",
    "        mae.reactions.get_by_id(rxn_id).upper_bound = 1000\n",
    "    \n",
    "    erg_vmax = {rxn_id:get_maximal_flux_through_given_rxn(mae,rxn_id,growth_id) for rxn_id in erg_rxns}\n",
    "    \n",
    "    rmax_vary_p = []\n",
    "    rmax_vary_p_rescue = []\n",
    "    \n",
    "    print('Simulate down regulation')\n",
    "    for p in ps:\n",
    "        with mae:\n",
    "            down_regulate_erg_genes(mae,erg_vmax,p)\n",
    "            rmax_vary_p.append(mae.optimize().objective_value)\n",
    "            \n",
    "            # rescue prot\n",
    "            for rxn_id,old_coeff in old_kcat_coeffs.items():\n",
    "                rxn = mae.reactions.get_by_id(rxn_id)\n",
    "                etc.change_rxn_coeff(rxn,met1,old_coeff)\n",
    "            \n",
    "            rxn = mae.reactions.get_by_id('draw_prot_{0}'.format('P32476'))\n",
    "            etc.change_rxn_coeff(rxn,met2,old_fnt_coeff)\n",
    "            rmax_vary_p_rescue.append(mae.optimize().objective_value)\n",
    "    return rmax_vary_p, rmax_vary_p_rescue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(particle,index,Q,T,ps):\n",
    "    \n",
    "    try:results = simulate_one_particle(particle,T,ps)\n",
    "    except: results = None\n",
    "    Q.put((index,results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = np.arange(0.01,1.01,0.01)\n",
    "T = 40 + 273.15\n",
    "outfile = '../results/down_regulate_erg_pathway_{0}.pkl'.format(int(T-273.15))\n",
    "particles = pickle.load(open('../results/smcabc_gem_three_conditions_save_all_particles.pkl','rb')).population\n",
    "\n",
    "Q = Manager().Queue()\n",
    "jobs = [Process(target=worker,args=(particle,index,Q,T,ps)) \n",
    "                               for index,particle in enumerate(particles)]\n",
    "\n",
    "for p in jobs: p.start()\n",
    "for p in jobs: p.join()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "results_population = [None for _ in particles] \n",
    "for index,res in [Q.get(timeout=1) for p in jobs]: results_population[index] = res\n",
    "pickle.dump([T,ps,results_population],open(outfile,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
